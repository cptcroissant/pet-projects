{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "SEED = 2202\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –∑–∞–∫–∞–∑! –î–æ—Å—Ç–∞–≤–∏–ª...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü–æ–∂–∞—Ä—Å–∫–∞—è –∫–æ—Ç–ª–µ—Ç–∞ –≤–∫—É—Å–Ω—é—â–∞—è! –°–ø–∞—Å–∏–±–æ)))</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ, —Å–ø–∞—Å–∏–±–æ, –∫–∞–∫ –≤—Å–µ–≥–¥–∞ –±—ã—Å—Ç—Ä–æ –∏ –≤–∫—É—Å–Ω–æ üëçüëå</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù–∞ —Ñ–æ—Ç–æ –±–ª–∏–Ω–æ–≤, –∏—Ö —Ç–∞–º 5  –£ –º–µ–Ω—è 3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>—è–π—Ü–æ –ø–∞—à–æ—Ç –ø—Ä–∏—à–ª–æ –≤–∫—Ä—É—Ç—É—é</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–ü—Ä–∏–≤–µ—Ç. –í–∫—É—Å–Ω–æ, –Ω–æ –±–µ–∑ —É–∫—Ä–∞—à–µ–Ω–∏–π.</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –í—á–µ—Ä–∞ –∑–∞–∫–∞–∑—ã–≤–∞–ª–∞ —Å–∞–ª–∞—Ç —Å –∞–≤–æ–∫–∞–¥–æ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>–£–ø–∞–∫–æ–≤–∫–∞ –Ω–µ —Ç–æ —á—Ç–æ –∫—Ä—É—Ç–∞—è - –∫–∞–∂–µ—Ç—Å—è –æ–Ω–∞ —Å–æ—Ö—Ä–∞–Ω...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"–°–ø–∞—Å–∏–±–æ –æ–≥—Ä–æ–º–Ω–æ–µ! –ë—ã—Å—Ç—Ä–æ –¥–æ—Å—Ç–∞–≤–∏–ª–∏\"</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"–Ø —Å–ª—É—á–∞–π–Ω–æ –æ–ø–ª–∞—Ç–∏–ª –∑–∞–∫–∞–∑ –¥–≤–∞–∂–¥—ã, –æ—Ç–º–µ–Ω–∏–ª –æ–¥–∏–Ω...</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  amount\n",
       "0  –°–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –∑–∞–∫–∞–∑! –î–æ—Å—Ç–∞–≤–∏–ª...       5\n",
       "1            –ü–æ–∂–∞—Ä—Å–∫–∞—è –∫–æ—Ç–ª–µ—Ç–∞ –≤–∫—É—Å–Ω—é—â–∞—è! –°–ø–∞—Å–∏–±–æ)))       5\n",
       "2    –°–ø–∞—Å–∏–±–æ, —Å–ø–∞—Å–∏–±–æ, –∫–∞–∫ –≤—Å–µ–≥–¥–∞ –±—ã—Å—Ç—Ä–æ –∏ –≤–∫—É—Å–Ω–æ üëçüëå       5\n",
       "3                 –ù–∞ —Ñ–æ—Ç–æ –±–ª–∏–Ω–æ–≤, –∏—Ö —Ç–∞–º 5  –£ –º–µ–Ω—è 3       1\n",
       "4                          —è–π—Ü–æ –ø–∞—à–æ—Ç –ø—Ä–∏—à–ª–æ –≤–∫—Ä—É—Ç—É—é     -20\n",
       "5                  –ü—Ä–∏–≤–µ—Ç. –í–∫—É—Å–Ω–æ, –Ω–æ –±–µ–∑ —É–∫—Ä–∞—à–µ–Ω–∏–π.     -20\n",
       "6  –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –í—á–µ—Ä–∞ –∑–∞–∫–∞–∑—ã–≤–∞–ª–∞ —Å–∞–ª–∞—Ç —Å –∞–≤–æ–∫–∞–¥–æ...       1\n",
       "7  –£–ø–∞–∫–æ–≤–∫–∞ –Ω–µ —Ç–æ —á—Ç–æ –∫—Ä—É—Ç–∞—è - –∫–∞–∂–µ—Ç—Å—è –æ–Ω–∞ —Å–æ—Ö—Ä–∞–Ω...       5\n",
       "8               \"–°–ø–∞—Å–∏–±–æ –æ–≥—Ä–æ–º–Ω–æ–µ! –ë—ã—Å—Ç—Ä–æ –¥–æ—Å—Ç–∞–≤–∏–ª–∏\"       5\n",
       "9  \"–Ø —Å–ª—É—á–∞–π–Ω–æ –æ–ø–ª–∞—Ç–∏–ª –∑–∞–∫–∞–∑ –¥–≤–∞–∂–¥—ã, –æ—Ç–º–µ–Ω–∏–ª –æ–¥–∏–Ω...     -20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('path_to_data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    525\n",
       "0    475\n",
       "Name: amount, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upd = df.copy()\n",
    "\n",
    "df_upd['amount'].replace(1,0, inplace=True)\n",
    "df_upd['amount'].replace(5,0, inplace=True)\n",
    "df_upd['amount'].replace(-20,1, inplace=True)\n",
    "\n",
    "df_upd['amount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_upd, test_size=0.1,\n",
    "                                             random_state=SEED, stratify=df_upd['amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train = train.to_csv('s_train.csv', index=False)\n",
    "s_test = test.to_csv('s_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119547"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer(vocab_file='../input/deeppavlov-ru-bert-model-deeppavlov/vocab_rubert.txt')\n",
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107685, 13842, 1758, 14992, 1468, 852, 12300, 106, 32803, 1758, 6762, 22337, 128, 4752, 36728, 88193, 842, 851, 28884, 2784, 106, 625, 74478, 7805, 68221, 33241, 852, 122, 122, 122, 122, 7805, 25567, 1468, 852, 21746, 128, 13231, 35676, 28636, 14825, 106, 122, 122]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(df.comment[0])\n",
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT = 512\n",
    "\n",
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:MAX_INPUT-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "fields = [('comment', TEXT), ('amount', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.TabularDataset(\n",
    "                            's_train.csv',\n",
    "                            format = 'csv', \n",
    "                            skip_header=True,\n",
    "                            fields = fields\n",
    ")\n",
    "\n",
    "test_data = data.TabularDataset(\n",
    "                            's_test.csv',\n",
    "                            format = 'csv', \n",
    "                            skip_header=True,\n",
    "                            fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0].amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[34005, 845, 52702, 842, 13526, 3618, 33242, 116155, 1523]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0].amount)\n",
    "print(test_data[0].comment)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[3240, 880, 852, 2226, 74176, 901, 3446, 4768, 106, 100]\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].amount)\n",
    "print(train_data[0].comment)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'1': 0, '0': 1})\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    batch_size = (BATCH_SIZE), \n",
    "    sort=False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_json_file(\n",
    "    '../input/bert-multi/bert_config.json')\n",
    "\n",
    "bert = BertModel.from_pretrained(\n",
    "    '../input/deeppavlov-ru-bert-model-deeppavlov/pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()    \n",
    "        self.bert = bert        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']     \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)     \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]       \n",
    "        _, hidden = self.rnn(embedded)\n",
    "\n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "\n",
    "        output = self.out(hidden)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 180,612,609 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,759,169 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()      \n",
    "        predictions = model(batch.comment).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.amount)\n",
    "        acc = binary_accuracy(predictions, batch.amount)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.comment).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.amount)\n",
    "            acc = binary_accuracy(predictions, batch.amount)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.373 | Train Acc: 83.65%\n",
      "\t Val. Loss: 0.408 |  Val. Acc: 83.51%\n",
      "Epoch: 02 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.349 | Train Acc: 83.96%\n",
      "\t Val. Loss: 0.406 |  Val. Acc: 84.11%\n",
      "Epoch: 03 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.326 | Train Acc: 86.46%\n",
      "\t Val. Loss: 0.423 |  Val. Acc: 86.28%\n",
      "Epoch: 04 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.347 | Train Acc: 85.62%\n",
      "\t Val. Loss: 0.366 |  Val. Acc: 86.46%\n",
      "Epoch: 05 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.425 | Train Acc: 79.17%\n",
      "\t Val. Loss: 0.408 |  Val. Acc: 84.11%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'classification.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {test_loss:.3f} |  Val. Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_example(sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:MAX_INPUT-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8517205119132996"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_example('—É –≤–∞—Å –æ—á–µ–Ω—å –≤–∫—É—Å–Ω—ã–π —Å—É–ø')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1030353382229805"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_example('–∫—É—Ä—å–µ—Ä –æ–ø–æ–∑–¥–∞–ª')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868089914321899"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_example('–≤–∫—É—Å–Ω–æ, –±—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â–µ —Ä–∞–∑')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771221041679382"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_example('–ø–∞–¥–∞–ª –ø—Ä–æ—à–ª–æ–≥–æ–¥–Ω–∏–π —Å–Ω–µ–≥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30844855308532715"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_example('—Å—É–ø —Å—Ç–∞—Ä—ã–π, –ø–∞—Å—Ç–∞ —Ç–≤–µ—Ä–¥–∞—è, –ø–∞—à–æ—Ç —Ä–∞–∑–≤–∞–ª–∏–ª—Å—è')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
